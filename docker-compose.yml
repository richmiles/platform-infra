services:
  # Reverse proxy with automatic HTTPS
  caddy:
    image: caddy:2-alpine
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
      - "443:443/udp" # HTTP/3
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy_data:/data
      - caddy_config:/config
    networks:
      - internal
    depends_on:
      - ieomd
      - umami
      - noodle
      - human-index
      - spark-swarm

  # Shared Postgres database
  postgres:
    image: postgres:16-alpine
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:?Set POSTGRES_PASSWORD in .env}
      POSTGRES_DB: postgres
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-db.sql:/docker-entrypoint-initdb.d/init-db.sql:ro
    networks:
      - internal
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # IEOMD Web - Caddy + static frontend (proxies /api to backend)
  ieomd:
    image: ghcr.io/richmiles/in-the-event-of-my-death-web:${IEOMD_IMAGE_TAG:-latest}
    restart: unless-stopped
    environment:
      SITE_ADDRESS: ":80" # Internal HTTP only (platform Caddy handles TLS)
    networks:
      - internal
    depends_on:
      - backend

  # IEOMD Backend - FastAPI (named "backend" to match IEOMD web Caddyfile)
  backend:
    image: ghcr.io/richmiles/in-the-event-of-my-death-backend:${IEOMD_IMAGE_TAG:-latest}
    restart: unless-stopped
    environment:
      DATABASE_URL: postgresql://${IEOMD_DB_USER:-ieomd}:${IEOMD_DB_PASSWORD:?Set IEOMD_DB_PASSWORD in .env}@postgres:5432/${IEOMD_DB_NAME:-ieomd_db}
      CORS_ORIGINS: ${IEOMD_CORS_ORIGINS:-["https://ieomd.com"]}
      # Object Storage (shared bucket with project prefix)
      # Prefer IEOMD_OBJECT_STORAGE_ENABLED; OBJECT_STORAGE_ENABLED is supported for backward compatibility.
      OBJECT_STORAGE_ENABLED: ${IEOMD_OBJECT_STORAGE_ENABLED:-${OBJECT_STORAGE_ENABLED:-false}}
      OBJECT_STORAGE_ENDPOINT: https://nyc3.digitaloceanspaces.com
      OBJECT_STORAGE_BUCKET: ${SPACES_BUCKET:-platform-storage}
      OBJECT_STORAGE_PREFIX: ${IEOMD_OBJECT_STORAGE_PREFIX:-ieomd}
      OBJECT_STORAGE_ACCESS_KEY: ${SPACES_ACCESS_KEY:-}
      OBJECT_STORAGE_SECRET_KEY: ${SPACES_SECRET_KEY:-}
      OBJECT_STORAGE_REGION: nyc3
      # Matrix Notifications (SparkSwarm ops alerts)
      MATRIX_HOMESERVER_URL: ${MATRIX_HOMESERVER_URL:-}
      MATRIX_ACCESS_TOKEN: ${MATRIX_ACCESS_TOKEN:-}
      MATRIX_ROOM_ID: ${MATRIX_ROOM_ID:-}
      # Environment identifier for alerts
      ENVIRONMENT: production
      # BTCPay Server (payment processing)
      BTCPAY_WEBHOOK_SECRET: ${BTCPAY_WEBHOOK_SECRET:-}
    networks:
      - internal
    depends_on:
      postgres:
        condition: service_healthy

  # Umami - Privacy-focused analytics
  umami:
    image: ghcr.io/umami-software/umami:postgresql-latest
    restart: unless-stopped
    environment:
      DATABASE_URL: postgresql://${UMAMI_DB_USER:-umami}:${UMAMI_DB_PASSWORD:?Set UMAMI_DB_PASSWORD in .env}@postgres:5432/${UMAMI_DB_NAME:-umami_db}
      APP_SECRET: ${UMAMI_APP_SECRET:?Set UMAMI_APP_SECRET in .env}
    networks:
      - internal
    depends_on:
      postgres:
        condition: service_healthy

  # Matrix/Synapse - SparkSwarm ops chat
  synapse:
    image: matrixdotorg/synapse:latest
    restart: unless-stopped
    environment:
      SYNAPSE_SERVER_NAME: chat.sparkswarm.com
      SYNAPSE_REPORT_STATS: "no"
      SYNAPSE_NO_TLS: "yes"
      SYNAPSE_ENABLE_REGISTRATION: "no"
      SYNAPSE_LOG_LEVEL: WARNING
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_DB: ${SYNAPSE_DB_NAME:-synapse_db}
      POSTGRES_USER: ${SYNAPSE_DB_USER:-synapse}
      POSTGRES_PASSWORD: ${SYNAPSE_DB_PASSWORD:?Set SYNAPSE_DB_PASSWORD in .env}
    volumes:
      - synapse_data:/data
    networks:
      - internal
    depends_on:
      postgres:
        condition: service_healthy

  # Noodle - Bar rating app
  noodle:
    image: ghcr.io/richmiles/noodle:${NOODLE_IMAGE_TAG:-latest}
    restart: unless-stopped
    volumes:
      - noodle_data:/app/data
    networks:
      - internal

  # Human Index - private recall utility (FastAPI + static frontend)
  human-index:
    image: ghcr.io/richmiles/human-index-app:${HUMAN_INDEX_IMAGE_TAG:-latest}
    restart: unless-stopped
    environment:
      DATABASE_URL: postgresql+psycopg://${HUMAN_INDEX_DB_USER:-human_index}:${HUMAN_INDEX_DB_PASSWORD:?Set HUMAN_INDEX_DB_PASSWORD in .env}@postgres:5432/${HUMAN_INDEX_DB_NAME:-human_index_db}
      CORS_ORIGINS: ${HUMAN_INDEX_CORS_ORIGINS:-["https://humanindex.io"]}
      ENVIRONMENT: ${HUMAN_INDEX_ENVIRONMENT:-production}
      PUBLIC_BASE_URL: ${HUMAN_INDEX_PUBLIC_BASE_URL:-https://humanindex.io}
      POSTMARK_API_TOKEN: ${HUMAN_INDEX_POSTMARK_API_TOKEN:?Set HUMAN_INDEX_POSTMARK_API_TOKEN in .env}
      MAIL_FROM: ${HUMAN_INDEX_MAIL_FROM:-Human Index <records@humanindex.io>}
      MAIL_REPLY_TO: ${HUMAN_INDEX_MAIL_REPLY_TO:-}
      SESSION_TTL_DAYS: ${HUMAN_INDEX_SESSION_TTL_DAYS:-30}
      SESSION_COOKIE_NAME: ${HUMAN_INDEX_SESSION_COOKIE_NAME:-humanindex_session}
    networks:
      - internal
    depends_on:
      postgres:
        condition: service_healthy

  # Spark Swarm - Project ecosystem dashboard
  spark-swarm:
    image: ghcr.io/richmiles/spark-swarm:${SPARK_SWARM_IMAGE_TAG:-latest}
    restart: unless-stopped
    environment:
      DATABASE_URL: postgresql://${SPARK_SWARM_DB_USER:-spark_swarm}:${SPARK_SWARM_DB_PASSWORD:?Set SPARK_SWARM_DB_PASSWORD in .env}@postgres:5432/${SPARK_SWARM_DB_NAME:-spark_swarm_db}
      AUTO_CREATE_TABLES: "true"
      SPARK_SWARM_MASTER_KEY: ${SPARK_SWARM_MASTER_KEY:?Set SPARK_SWARM_MASTER_KEY in .env}
      SPARK_SWARM_API_KEY: ${SPARK_SWARM_API_KEY:?Set SPARK_SWARM_API_KEY in .env}
      SPARK_SWARM_AUTH_DISABLED: ${SPARK_SWARM_AUTH_DISABLED:-false}
    networks:
      - internal
    depends_on:
      postgres:
        condition: service_healthy

networks:
  internal:
    driver: bridge

volumes:
  postgres_data:
  caddy_data:
  caddy_config:
  synapse_data:
  noodle_data:
